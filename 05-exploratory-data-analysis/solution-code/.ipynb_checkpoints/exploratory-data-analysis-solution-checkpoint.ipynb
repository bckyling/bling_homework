{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# Pandas for Exploratory Data Analysis\n",
    "\n",
    "_Authors: Kevin Markham (DC)_\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Objectives\n",
    "\n",
    "- **Define** what Pandas is and how it relates to data science\n",
    "- **Manipulate** Pandas DataFrames and Series\n",
    "- **Filter and sort** data using Pandas\n",
    "- **Manipulate** DataFrame columns\n",
    "- **Know** how to handle null and missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lesson Guide\n",
    "\n",
    "- [What is Pandas](#pandas)\n",
    "- [Reading Files, Selecting Columns, and Summarizing](#reading-files)\n",
    "    - [EXERCISE ONE](#exercise-one)\n",
    "    \n",
    "    \n",
    "- [Filtering and Sorting](#filtering-and-sorting)\n",
    "    - [EXERCISE TWO](#exercise-two)\n",
    "    \n",
    "    \n",
    "- [Renaming, Adding, and Removing Columns](#columns)\n",
    "- [Handling Missing Values](#missing-values)\n",
    "    - [EXERCISE THREE](#exercise-three)\n",
    "    \n",
    "    \n",
    "- [Split-Apply-Combine](#split-apply-combine)\n",
    "    - [EXERCISE FOUR](#exercise-four)\n",
    "    \n",
    "    \n",
    "- [Selecting Multiple Columns and Filtering Rows](#multiple-columns)\n",
    "- [Joining (Merging) DataFrames](#joining-dataframes)\n",
    "- [OPTIONAL: Other Commonly Used Features](#other-features)\n",
    "- [OPTIONAL: Other Less Used Features of Pandas](#uncommon-features)\n",
    "- [Summary](#summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"pandas\"></a>\n",
    "\n",
    "## What is Pandas\n",
    "\n",
    "- **Objective:** **Define** what Pandas is and how it relates to data science\n",
    "\n",
    "Pandas is a Python library that primarily adds two new datatypes to Python: `DataFrame` and `Series`.\n",
    "\n",
    "- A `Series` is a sequence of items, where each item has a unique label (called an `index`).\n",
    "- A `DataFrame` is a table of data. Each row has a unique label (the `row index`), and each column has a unique label (the `column index`)\n",
    "- Note that each column in a `DataFrame` can be considered a `Series`. (`Series` index).\n",
    "\n",
    "> Behind the scenes, these datatypes use the NumPy library (\"Numerical Python\"). NumPy primarily adds the `ndarray` (n-dimensional array) datatype to Pandas. An `ndarray` is similar to a Python list -- it stores ordered data. However, it differs in three respects:\n",
    "> - Each element has the same datatype (typically fixed-size, e.g. a 32-bit integer).\n",
    "> - Elements are stored contiguously (immediately after each other) in memory for fast retrieval.\n",
    "> - The total size of an `ndarray` is fixed.\n",
    "\n",
    "> Storing `Series` and `DataFrame` data in `ndarray`s makes Pandas faster and use less memory than standard Python datatypes. Many libraries (such as scikit-learn) accept `ndarray`s as input rather than Pandas datatypes, so we will frequently convert between them.\n",
    "\n",
    "\n",
    "### Using Pandas\n",
    "\n",
    "Pandas is frequently used in data science because it offers a large set of commonly used functions, is relatively fast, and has a large community. Because many data science libraries also use NumPy to manipulate data, you can easily transfer data between libraries (as we will often do in this class!).\n",
    "\n",
    "Pandas is a large library that typically takes a lot of practice to learn. It heavily overrides Python operators, resulting in odd-looking syntax. For example, given a `DataFrame` called `cars` which contains a column `mpg`, we might want to view all cars with mpg over 35. To do this, we might write: `cars[cars['mpg'] > 35]`. In standard Python, this would most likely give a syntax error. (**Challenge:** Using only built-in datatypes, can you define `cars` and `mpg` to make this expression valid?)\n",
    "\n",
    "Pandas also highly favors certain patterns of use. For example, looping through a DataFrame row-by-row is highly discouraged. Instead, Pandas favors using **vectorized functions** that operate column-by-column. (This is because each column is stored separately as an ndarray, and NumPy is optimized for operating on ndarrays!)\n",
    "\n",
    "Do not be discouraged if Pandas feels overwhelming. Gradually as you use it, you will become familiar with which methods to use and the \"Pandas way\" of thinking about and manipulating data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class methods and attributes\n",
    "\n",
    "Pandas `DataFrame`s are Pandas class objects and therefore come with attributes and methods. To access these, follow the variable name with a dot. For example, given a `DataFrame` called `users`:\n",
    "\n",
    "```\n",
    "- users.index       # accesses the `index` attribute -- note there are no parentheses. attributes are not callable\n",
    "- users.head()      # calls the `head` method (since there are open/closed parentheses)\n",
    "- users.head(10)    # calls the `head` method with parameter `10`, indicating the first 10 rows. this is the same as:\n",
    "- users.head(n=10)  # calls the `head` method, setting the named parameter `n` to have a value of `10`.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Viewing Documentation\n",
    "\n",
    "There are a few ways to find more information about a method.\n",
    "\n",
    "**Method 1:** In Jupyter, you can quickly view documentation for a method by following the method name by a `?`, as follows:\n",
    "\n",
    "```\n",
    "users.head?\n",
    "```\n",
    "\n",
    "> ```\n",
    "Signature: users.head(n=5)\n",
    "Docstring: Returns first n rows\n",
    "```\n",
    "\n",
    "Notice that we would normally invoke this method by calling `users.head(5)`. One quirk of IPython is that the `?` symbol must be the last character in the cell. Otherwise, it might not work.\n",
    "\n",
    "> The `?` is a shortcut for the built-in Python function `help`, which returns the method's docstring. For example:\n",
    "> ```\n",
    "help(users.head)\n",
    "```\n",
    "\n",
    "**Method 2:** You can also search online for the phrase \"`DataFrame head`\", since you are calling the method `head` on the `users` object, which happens to be a `DataFrame`. (`type(users) => pandas.DataFrame`)\n",
    "\n",
    "You can alternatively search online for `pandas head`, but be careful! `DataFrame` and `Series` both have a `head` method, so make sure you view the documentation for the correct one since they might be called differently. You will know you are looking at the correct documentation page because it will say `DataFrame.head` at the top, instead of `Series.head`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T22:39:32.382440Z",
     "start_time": "2018-04-03T22:39:31.589430Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load pandas into python\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"reading-files\"></a>\n",
    "### Reading Files, Selecting Columns, and Summarizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T22:39:32.600253Z",
     "start_time": "2018-04-03T22:39:32.384384Z"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'./data/user.tbl' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-a8e77c3a0ae9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# read 'u.user' into 'users'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0musers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./data/user.tbl'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'|'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/Stefan/.virtualenvs/datacamp/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    644\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    645\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 646\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    647\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Stefan/.virtualenvs/datacamp/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 389\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mchunksize\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Stefan/.virtualenvs/datacamp/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    728\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 730\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    731\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    732\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Stefan/.virtualenvs/datacamp/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m    921\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 923\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    924\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Stefan/.virtualenvs/datacamp/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1388\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'allow_leading_cols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1390\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_parser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1392\u001b[0m         \u001b[0;31m# XXX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader.__cinit__ (pandas/parser.c:4184)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader._setup_parser_source (pandas/parser.c:8449)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: File b'./data/user.tbl' does not exist"
     ]
    }
   ],
   "source": [
    "# read 'u.user' into 'users'\n",
    "users = pd.read_table('./data/user.tbl', sep='|')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Examine the users data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T22:39:32.601105Z",
     "start_time": "2018-04-03T22:39:31.610Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "users                   # print the first 30 and last 30 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T22:39:32.601976Z",
     "start_time": "2018-04-03T22:39:31.616Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "type(users)             # DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T22:39:32.602913Z",
     "start_time": "2018-04-03T22:39:31.620Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "users.head()            # print the first 5 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T22:39:32.604710Z",
     "start_time": "2018-04-03T22:39:31.625Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "users.head(10)          # print the first 10 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T22:39:32.605833Z",
     "start_time": "2018-04-03T22:39:31.631Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "users.tail()            # print the last 5 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T22:39:32.607519Z",
     "start_time": "2018-04-03T22:39:31.635Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " # the row index (aka \"the row labels\" -- in this case integers)\n",
    "users.index            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T22:39:32.608816Z",
     "start_time": "2018-04-03T22:39:31.639Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# column names (which is \"an index\")\n",
    "users.columns           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T22:39:32.609924Z",
     "start_time": "2018-04-03T22:39:31.643Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data types of each column -- each column is stored as an ndarray which has a data type\n",
    "users.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T22:39:32.611090Z",
     "start_time": "2018-04-03T22:39:31.647Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# number of rows and columns\n",
    "users.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T22:39:32.612155Z",
     "start_time": "2018-04-03T22:39:31.651Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# all values as a numpy array\n",
    "users.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T22:39:32.613364Z",
     "start_time": "2018-04-03T22:39:31.655Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# concise summary (including memory usage) -- useful to quickly see if nulls exist\n",
    "users.info()            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Selecting or indexing data**\n",
    "Pandas `DataFrame`s have structural similarities with Python-style lists and dictionaries.  \n",
    "In the example below, we select a column of data using the name of the column in a similar manner to how we select a dictionary value with the dictionary key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T22:39:32.614309Z",
     "start_time": "2018-04-03T22:39:31.664Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# select a column - returns a Pandas 'Series' (essentially an ndarray with an index)\n",
    "users['gender']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T22:39:32.615670Z",
     "start_time": "2018-04-03T22:39:31.668Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 'DataFrame' columns are Pandas 'Series'\n",
    "type(users['gender'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T22:39:32.616926Z",
     "start_time": "2018-04-03T22:39:31.673Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# select one column using the DataFrame attribute\n",
    "users.gender\n",
    "\n",
    "# while a useful shorthand, these attributes only exist\n",
    "# if the column name has no punctuations or spaces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**summarize (describe) the data**\n",
    "Pandas has a bunch of built in methods to quickly summaraize your data and provide you with a quick general understanding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T22:39:32.618128Z",
     "start_time": "2018-04-03T22:39:31.681Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# describe all numeric columns\n",
    "users.describe()                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T22:39:32.622994Z",
     "start_time": "2018-04-03T22:39:31.686Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# describe all object columns (can include multiple types)\n",
    "users.describe(include=['object'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T22:39:32.624288Z",
     "start_time": "2018-04-03T22:39:31.691Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# describe all columns, including non-numeric\n",
    "users.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T22:39:32.625227Z",
     "start_time": "2018-04-03T22:39:31.696Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# describe a single column -- recall that 'users.gender' refers to a Series\n",
    "users.gender.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T22:39:32.626116Z",
     "start_time": "2018-04-03T22:39:31.700Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# calculate the mean of the ages\n",
    "users.age.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T22:39:32.627140Z",
     "start_time": "2018-04-03T22:39:31.704Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# draw a histogram of a column (the distribution of ages)\n",
    "users.age.hist();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Count the number of occurrences of each value**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T22:39:32.628124Z",
     "start_time": "2018-04-03T22:39:31.709Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "users.gender.value_counts()     # most useful for categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T22:39:32.629063Z",
     "start_time": "2018-04-03T22:39:31.714Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "users.gender.value_counts().plot(kind='bar')     # quick plot by category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T22:39:32.630090Z",
     "start_time": "2018-04-03T22:39:31.717Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# can also be used with numeric variables\n",
    "#   try .sort_index() to sort by indices or .sort_values() to sort by counts\n",
    "users.age.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T22:39:32.630968Z",
     "start_time": "2018-04-03T22:39:31.722Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "users.age.value_counts().sort_index().plot(kind='bar', figsize=(12,12));     # bigger plot by increasing age\n",
    "plt.xlabel('Age');\n",
    "plt.ylabel('Number of users');\n",
    "plt.title('Number of users per age');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"exercise-one\"></a>\n",
    "### EXERCISE ONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T22:39:32.632718Z",
     "start_time": "2018-04-03T22:39:31.726Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read drinks.csv into a DataFrame called 'drinks'\n",
    "import pandas as pd\n",
    "drinks = pd.read_csv('../data/drinks.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T22:39:32.633744Z",
     "start_time": "2018-04-03T22:39:31.730Z"
    }
   },
   "outputs": [],
   "source": [
    "# print the head and the tail\n",
    "drinks.head()\n",
    "\n",
    "drinks.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T22:39:32.634796Z",
     "start_time": "2018-04-03T22:39:31.734Z"
    }
   },
   "outputs": [],
   "source": [
    "# examine the default index, data types, and shape\n",
    "\n",
    "print(drinks.index)\n",
    "\n",
    "print(drinks.dtypes)\n",
    "\n",
    "print(drinks.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T22:39:32.635805Z",
     "start_time": "2018-04-03T22:39:31.738Z"
    }
   },
   "outputs": [],
   "source": [
    "# print the 'beer_servings' Series\n",
    "\n",
    "drinks['beer_servings']\n",
    "#or\n",
    "drinks.beer_servings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T22:39:32.636674Z",
     "start_time": "2018-04-03T22:39:31.741Z"
    }
   },
   "outputs": [],
   "source": [
    "# calculate the average 'beer_servings' for the entire dataset\n",
    "\n",
    "drinks['beer_servings'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T22:39:32.637609Z",
     "start_time": "2018-04-03T22:39:31.746Z"
    }
   },
   "outputs": [],
   "source": [
    "# count the number of occurrences of each 'continent' value and see if it looks correct\n",
    "\n",
    "drinks['continent'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T22:39:32.638548Z",
     "start_time": "2018-04-03T22:39:31.749Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Does not look correct.  Where is NA, North America?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"filtering-and-sorting\"></a>\n",
    "### Filtering and Sorting\n",
    "- **Objective:** **Filter and sort** data using Pandas\n",
    "\n",
    "We can use simple operator comparisons on columns to extract relevant or drop irrelevant information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**logical filtering: only show users with age < 20**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T22:39:32.639472Z",
     "start_time": "2018-04-03T22:39:31.757Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a Series of booleans...\n",
    "# in Pandas, this comparison is performed element-wise on each row of data\n",
    "young_bool = users.age < 20\n",
    "young_bool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T22:39:32.640442Z",
     "start_time": "2018-04-03T22:39:31.763Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ...and use that Series to filter rows\n",
    "# in Pandas, indexing a DataFrame by a Series of booleans only selects rows that are True in the boolean\n",
    "users[young_bool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T22:39:32.641836Z",
     "start_time": "2018-04-03T22:39:31.770Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# or, combine into a single step\n",
    "users[users.age < 20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T22:39:32.643538Z",
     "start_time": "2018-04-03T22:39:31.773Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Important: This creates a view of the original DataFrame, not a new DataFrame.\n",
    "# If you alter this view (e.g., by storing it in a variable and altering that)\n",
    "# You will alter only the slice of the DataFrame and not the actual DataFrame itself\n",
    "# Here, notice that Pandas gives you a SettingWithCopyWarning to alert you of this.\n",
    "\n",
    "# It is best practice to use .loc and .iloc instead of the syntax below\n",
    "\n",
    "users_under20 = users[users.age < 20]   # to resolve this warning, copy the DataFrame using .copy()\n",
    "users_under20['newcolumn'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T22:39:32.645873Z",
     "start_time": "2018-04-03T22:39:31.777Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# select one column from the filtered results\n",
    "users[users.age < 20].occupation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T22:39:32.647307Z",
     "start_time": "2018-04-03T22:39:31.781Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# value_counts of resulting Series\n",
    "users[users.age < 20].occupation.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**logical filtering with multiple conditions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T22:39:32.648370Z",
     "start_time": "2018-04-03T22:39:31.791Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ampersand for AND condition. (this is a \"bitwise\" AND)\n",
    "# important: you MUST put parentheses around each expression because '&' has a higher precedence than '<'!\n",
    "users[(users.age < 20) & (users.gender=='M')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T22:39:32.649518Z",
     "start_time": "2018-04-03T22:39:31.809Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pipe for OR condition. (this is a \"bitwise\" OR)\n",
    "# important: you MUST put parentheses around each expression because '|' has a higher precedence than '<'!\n",
    "users[(users.age < 20) | (users.age > 60)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T22:39:32.650556Z",
     "start_time": "2018-04-03T22:39:31.813Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# preferred alternative to multiple OR conditions\n",
    "users[users.occupation.isin(['doctor', 'lawyer'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sorting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T22:39:32.653854Z",
     "start_time": "2018-04-03T22:39:31.818Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sort a Series\n",
    "users.age.sort_values()                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T22:39:32.654785Z",
     "start_time": "2018-04-03T22:39:31.825Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sort a DataFrame by a single column\n",
    "users.sort_values('age') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T22:39:32.655644Z",
     "start_time": "2018-04-03T22:39:31.832Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# use descending order instead\n",
    "users.sort_values('age', ascending=False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T22:39:32.656527Z",
     "start_time": "2018-04-03T22:39:31.839Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sort by multiple columns\n",
    "users.sort_values(['occupation', 'age'])  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"exercise-two\"></a>\n",
    "### EXERCISE TWO\n",
    "Use the `drinks.csv` or `drinks` dataframe from earlier to complete the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T22:39:32.657403Z",
     "start_time": "2018-04-03T22:39:31.855Z"
    }
   },
   "outputs": [],
   "source": [
    "# filter DataFrame to only include European countries\n",
    "\n",
    "drinks[drinks['continent'] == 'EU']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T22:39:32.659804Z",
     "start_time": "2018-04-03T22:39:31.860Z"
    }
   },
   "outputs": [],
   "source": [
    "# filter DataFrame to only include European countries with wine_servings > 300\n",
    "\n",
    "drinks[(drinks['continent'] == 'EU') & (drinks['wine_servings'] > 300)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T22:39:32.660730Z",
     "start_time": "2018-04-03T22:39:31.864Z"
    }
   },
   "outputs": [],
   "source": [
    "# calculate the average 'beer_servings' for all of Europe\n",
    "\n",
    "drinks[drinks['continent'] == 'EU']['beer_servings'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T22:39:32.661681Z",
     "start_time": "2018-04-03T22:39:31.868Z"
    }
   },
   "outputs": [],
   "source": [
    "# determine which 10 countries have the highest total_litres_of_pure_alcohol\n",
    "drinks[['country','total_litres_of_pure_alcohol']].sort_values(by='total_litres_of_pure_alcohol',ascending=False).head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"columns\"></a>\n",
    "### Renaming, Adding, and Removing Columns\n",
    "\n",
    "- **Objective:** **Manipulate** DataFrame columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T22:39:32.663714Z",
     "start_time": "2018-04-03T22:39:31.873Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Are beer servings and spirit servings correlated?\n",
    "drinks.plot(kind='scatter', x='beer_servings', y='spirit_servings')\n",
    "\n",
    "print((drinks.corr()['beer_servings']))  # Correlation coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T22:39:32.664938Z",
     "start_time": "2018-04-03T22:39:31.880Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# renaming one or more columns in a single output using value mapping\n",
    "drinks.rename(columns={'beer_servings':'beer', 'wine_servings':'wine'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T22:39:32.674110Z",
     "start_time": "2018-04-03T22:39:31.883Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# renaming one or more columns in the original DataFrame\n",
    "drinks.rename(columns={'beer_servings':'beer', 'wine_servings':'wine'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T22:39:32.675192Z",
     "start_time": "2018-04-03T22:39:31.888Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# replace all column names using a list of matching length\n",
    "drink_cols = ['country', 'beer', 'spirit', 'wine', 'liters', 'continent'] \n",
    "\n",
    "# replace during file reading (disables the header from the file)\n",
    "drinks = pd.read_csv('data/drinks.csv', header=0, names=drink_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T22:39:32.676279Z",
     "start_time": "2018-04-03T22:39:31.892Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# replace after file has already been read into python\n",
    "drinks.columns = drink_cols "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Easy Column Operations**\n",
    "Rather than having to reference indexes and creating for loops to do column wise operations, Pandas is smart and knows that when we add columns together we want to add the values in each rows together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T22:39:32.677184Z",
     "start_time": "2018-04-03T22:39:31.897Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# add a new column as a function of existing columns\n",
    "drinks['servings'] = drinks.beer + drinks.spirit + drinks.wine\n",
    "drinks['mL'] = drinks.liters * 1000\n",
    "\n",
    "drinks.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Removing Columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T22:39:32.678121Z",
     "start_time": "2018-04-03T22:39:31.902Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# axis=0 for rows, 1 for columns\n",
    "drinks.drop('mL', axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T22:39:32.679128Z",
     "start_time": "2018-04-03T22:39:31.904Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# drop multiple columns\n",
    "drinks.drop(['mL', 'servings'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T22:39:32.680100Z",
     "start_time": "2018-04-03T22:39:31.907Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# drop on the original DataFrame rather than returning a new one\n",
    "drinks.drop(['mL', 'servings'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"missing-values\"></a>\n",
    "### Handling Missing Values\n",
    "\n",
    "- **Objective:** **Know** how to handle null and missing values\n",
    "\n",
    "Sometimes, values will be missing from the source data or as a byproduct of manipulations. It is very important to detect missing data. Missing data can:\n",
    "\n",
    "- Make the entire row ineligible to be training data for a model.\n",
    "- Hint at data collection errors.\n",
    "- Indicate improper conversion or manipulation.\n",
    "- Actually not be missing -- it sometimes means \"zero\", \"false\", \"not applicable\", or \"entered an empty string\"\n",
    "\n",
    "For example, a CSV file might have a missing value in some data fields:\n",
    "\n",
    "```\n",
    "tool_name,material,cost\n",
    "hammer,wood,8\n",
    "chainsaw,,\n",
    "wrench,metal,5\n",
    "```\n",
    "\n",
    "When this data is imported, \"null\" values will be stored in the second row (in the \"material\" and \"cost\" columns).\n",
    "\n",
    "> In Pandas, a \"null\" value is either `None` or `np.NaN` (Not a Number). Many fixed-size numeric datatypes (such as integers) do not have a way of representing `np.NaN`. So, numeric columns will be promoted to floating-point data types which do support it. For example, when importing the CSV file above:\n",
    "\n",
    "> - **For the second row:** `None` will be stored in the \"material\" column and `np.NaN` will be stored in the \"cost\" column. The entire \"cost\" column (stored as a single `ndarray`) must be stored as floating-point values to accommodate the `np.NaN`, even though an integer `8` is in the first row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T22:39:32.681066Z",
     "start_time": "2018-04-03T22:39:31.912Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# missing values are usually excluded in calculations by default\n",
    "drinks.continent.value_counts()              # excludes missing values in the calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T22:39:32.682013Z",
     "start_time": "2018-04-03T22:39:31.915Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# includes missing values\n",
    "drinks.continent.value_counts(dropna=False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T22:39:32.682954Z",
     "start_time": "2018-04-03T22:39:31.918Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# find missing values in a Series\n",
    "# True if missing, False if not missing\n",
    "drinks.continent.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T22:39:32.687449Z",
     "start_time": "2018-04-03T22:39:31.921Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# count the missing values - sum() works because True is 1 and False is 0\n",
    "drinks.continent.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T22:39:32.688409Z",
     "start_time": "2018-04-03T22:39:31.924Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# True if not missing, False if missing\n",
    "drinks.continent.notnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T22:39:32.689324Z",
     "start_time": "2018-04-03T22:39:31.928Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# only show rows where continent is not missing\n",
    "drinks[drinks.continent.notnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Understanding Pandas Axis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T22:39:32.690250Z",
     "start_time": "2018-04-03T22:39:31.931Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sums \"down\" the 0 axis (rows) -- so, we get the sums of each column\n",
    "drinks.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T22:39:32.691165Z",
     "start_time": "2018-04-03T22:39:31.935Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# axis=0 is the default\n",
    "drinks.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T22:39:32.692093Z",
     "start_time": "2018-04-03T22:39:31.937Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sums \"across\" the 1 axis (columns) -- so, we get the sums of numeric values in the row (beer+spirit+wine+liters+...)\n",
    "drinks.sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Find missing values in a DataFrame**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T22:39:32.693056Z",
     "start_time": "2018-04-03T22:39:31.941Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# DataFrame of booleans\n",
    "drinks.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T22:39:32.694004Z",
     "start_time": "2018-04-03T22:39:31.945Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# count the missing values in each column -- remember by default, axis=0\n",
    "print((drinks.isnull().sum()))\n",
    "\n",
    "drinks.isnull().sum().plot(kind='bar');         # visually\n",
    "plt.title('Number of null values per column');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dropping Missing Values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T22:39:32.694980Z",
     "start_time": "2018-04-03T22:39:31.950Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# drop a row if ANY values are missing from any column -- can be dangerous!\n",
    "drinks.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T22:39:32.696032Z",
     "start_time": "2018-04-03T22:39:31.954Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# drop a row only if ALL values are missing\n",
    "drinks.dropna(how='all')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Filling Missing Values**\n",
    "If you noticed the continent North American, NA, does not appear in the `continent` column.  Pandas read in the original data and saw 'NA' and thought it was a missing value and converted it to a 'NaN', missing value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T22:39:32.697805Z",
     "start_time": "2018-04-03T22:39:31.957Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fill in missing values with 'NA' -- this is dangerous to do without manually verifying them!\n",
    "drinks.continent.fillna(value='NA')                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T22:39:32.699116Z",
     "start_time": "2018-04-03T22:39:31.960Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# modifies 'drinks' in-place\n",
    "drinks.continent.fillna(value='NA', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T22:39:32.700182Z",
     "start_time": "2018-04-03T22:39:31.964Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# turn off the missing value filter -- better approach!\n",
    "drinks = pd.read_csv('../data/drinks.csv', header=0, names=drink_cols, na_filter=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"exercise-three\"></a>\n",
    "### EXERCISE THREE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T22:39:32.701200Z",
     "start_time": "2018-04-03T22:39:31.968Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read ufo.csv into a DataFrame called 'ufo'\n",
    "ufo_data = '../data/ufo.csv'\n",
    "ufo = pd.read_csv(ufo_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T22:39:32.702215Z",
     "start_time": "2018-04-03T22:39:31.972Z"
    }
   },
   "outputs": [],
   "source": [
    "ufo.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T22:39:32.703396Z",
     "start_time": "2018-04-03T22:39:31.974Z"
    }
   },
   "outputs": [],
   "source": [
    "# check the shape of the DataFrame\n",
    "ufo.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T22:39:32.704461Z",
     "start_time": "2018-04-03T22:39:31.978Z"
    }
   },
   "outputs": [],
   "source": [
    "# what are the three most common colors reported?\n",
    "ufo['Colors Reported'].value_counts().head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T22:39:32.705461Z",
     "start_time": "2018-04-03T22:39:31.980Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# rename any columns with spaces so that they don't contain spaces\n",
    "\n",
    "ufo.columns = ['City', 'Colors_Reported','Shape_Reported','State','Time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T22:39:32.706599Z",
     "start_time": "2018-04-03T22:39:31.984Z"
    }
   },
   "outputs": [],
   "source": [
    "# for reports in VA, what's the most common city?\n",
    "ufo[ufo['State'] == 'VA']['City'].value_counts().head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T22:39:32.721140Z",
     "start_time": "2018-04-03T22:39:31.989Z"
    }
   },
   "outputs": [],
   "source": [
    "# print a DataFrame containing only reports from Arlington, VA\n",
    "ufo[(ufo['State']=='VA')&(ufo['City']=='Arlington')].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T22:39:32.722531Z",
     "start_time": "2018-04-03T22:39:31.991Z"
    }
   },
   "outputs": [],
   "source": [
    "# count the number of missing values in each column\n",
    "ufo.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T22:39:32.723858Z",
     "start_time": "2018-04-03T22:39:31.995Z"
    }
   },
   "outputs": [],
   "source": [
    "# how many rows remain if you drop all rows with any missing values?\n",
    "ufo.dropna().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"split-apply-combine\"></a>\n",
    "### Split-Apply-Combine\n",
    "\n",
    "Split-Apply-Combine is a pattern for analyzing data. Suppose we want to find mean beer consumption per country. Then:\n",
    "\n",
    "- **Split:** We group data by continent.\n",
    "- **Apply:** For each group, we apply the mean() function to find the average beer consumption.\n",
    "- **Combine:** We now combine the continent names with the mean()s to produce a summary of our findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T22:39:32.726034Z",
     "start_time": "2018-04-03T22:39:31.999Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for each continent, calculate the mean beer servings\n",
    "drinks.groupby('continent').beer.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T22:39:32.728074Z",
     "start_time": "2018-04-03T22:39:32.003Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for each continent, calculate the mean of all numeric columns\n",
    "drinks.groupby('continent').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T22:39:32.729660Z",
     "start_time": "2018-04-03T22:39:32.005Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for each continent, describe beer servings\n",
    "drinks.groupby('continent').beer.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T22:39:32.731447Z",
     "start_time": "2018-04-03T22:39:32.010Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# similar, but outputs a DataFrame and can be customized -- \"agg\" allows you to aggregate results of Series functions\n",
    "drinks.groupby('continent').beer.agg(['count', 'mean', 'min', 'max'])\n",
    "drinks.groupby('continent').beer.agg(['count', 'mean', 'min', 'max']).sort_values('mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T22:39:32.732505Z",
     "start_time": "2018-04-03T22:39:32.014Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for each continent, describe all numeric columns\n",
    "drinks.groupby('continent').describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T22:39:32.733703Z",
     "start_time": "2018-04-03T22:39:32.018Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for each continent, count the number of rows\n",
    "print((drinks.groupby('continent').continent.count()))\n",
    "print((drinks.continent.value_counts()))   # should be the same"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"exercise-four\"></a>\n",
    "### EXERCISE FOUR\n",
    "\n",
    "Use the `Users` dataframe or `users` file in the Data folder to complete the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T22:39:32.734813Z",
     "start_time": "2018-04-03T22:39:32.022Z"
    }
   },
   "outputs": [],
   "source": [
    "users.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T22:39:32.736039Z",
     "start_time": "2018-04-03T22:39:32.025Z"
    }
   },
   "outputs": [],
   "source": [
    "# for each occupation in 'users', count the number of occurrences\n",
    "users['occupation'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T22:39:32.736963Z",
     "start_time": "2018-04-03T22:39:32.029Z"
    }
   },
   "outputs": [],
   "source": [
    "# for each occupation, calculate the mean age\n",
    "users.groupby('occupation')['age'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T22:39:32.738215Z",
     "start_time": "2018-04-03T22:39:32.035Z"
    }
   },
   "outputs": [],
   "source": [
    "# for each occupation, calculate the minimum and maximum ages\n",
    "users.groupby('occupation')['age'].agg(['min', 'max'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T22:39:32.738957Z",
     "start_time": "2018-04-03T22:39:32.038Z"
    }
   },
   "outputs": [],
   "source": [
    "# for each combination of occupation and gender, calculate the mean age\n",
    "users.groupby(['occupation','gender'])['age'].mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"multiple-columns\"></a>\n",
    "### Selecting Multiple Columns and Filtering Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T22:39:32.739855Z",
     "start_time": "2018-04-03T22:39:32.044Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# select multiple columns -- yet another overload of the DataFrame indexing operator!\n",
    "my_cols = ['City', 'State']     # create a list of column names...\n",
    "ufo[my_cols]                    # ...and use that list to select columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T22:39:32.740957Z",
     "start_time": "2018-04-03T22:39:32.047Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# or, combine into a single step (this is a Python list inside of the Python index operator!)\n",
    "ufo[['City', 'State']]          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Use `loc` to select columns by name**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T22:39:32.742013Z",
     "start_time": "2018-04-03T22:39:32.052Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 'loc' locates the values from the first parameter (colon means \"all rows\"), and the column 'City'\n",
    "ufo.loc[:, 'City']   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T22:39:32.743196Z",
     "start_time": "2018-04-03T22:39:32.055Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# select two columns\n",
    "ufo.loc[:, ['City', 'State']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T22:39:32.744308Z",
     "start_time": "2018-04-03T22:39:32.059Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# select a range of columns -- unlike Python ranges, Pandas index ranges INCLUDE the final column in the range\n",
    "ufo.loc[:, 'City':'State']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T22:39:32.745447Z",
     "start_time": "2018-04-03T22:39:32.061Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# loc can also filter rows by \"name\" (the index)\n",
    "# row 0, all columns\n",
    "ufo.loc[0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T22:39:32.746394Z",
     "start_time": "2018-04-03T22:39:32.066Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# rows 0/1/2, all columns\n",
    "ufo.loc[0:2, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T22:39:32.746979Z",
     "start_time": "2018-04-03T22:39:32.070Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# rows 0/1/2, range of columns\n",
    "ufo.loc[0:2, 'City':'State'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T22:39:32.747930Z",
     "start_time": "2018-04-03T22:39:32.073Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# use iloc to filter rows and select columns by integer position\n",
    "# (remember that rows/columns use indices, so iloc lets you refer to indices via their index rather than value!)\n",
    "# all rows, columns in position 0/3 (City/State)\n",
    "ufo.iloc[:, [0, 3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T22:39:32.749042Z",
     "start_time": "2018-04-03T22:39:32.076Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# all rows, columns in position 0/1/2/3\n",
    "# subtly, note here it is NOT INCLUDING 4 because this is an integer range, not a Pandas index range!\n",
    "ufo.iloc[:, 0:4] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T22:39:32.750295Z",
     "start_time": "2018-04-03T22:39:32.079Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# rows in position 0/1/2, all columns\n",
    "ufo.iloc[0:3, :] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"joining-dataframes\"></a>\n",
    "### Joining (Merging) DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T22:39:32.751294Z",
     "start_time": "2018-04-03T22:39:32.086Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read 'u.item' into 'movies'\n",
    "import pandas as pd\n",
    "movie_cols = ['movie_id', 'title']\n",
    "u_item = '../data/movies.tbl'\n",
    "movies = pd.read_table(u_item, sep='|', header=None, names=movie_cols, usecols=[0, 1], encoding='latin-1')\n",
    "movies.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T22:39:32.752504Z",
     "start_time": "2018-04-03T22:39:32.089Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read 'u.data' into 'ratings'\n",
    "rating_cols = ['user_id', 'movie_id', 'rating', 'timestamp']\n",
    "u_data = '../data/movie_ratings.tsv'\n",
    "ratings = pd.read_table(u_data, sep='\\t', header=None, names=rating_cols)\n",
    "ratings.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T22:39:32.753684Z",
     "start_time": "2018-04-03T22:39:32.095Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# merge 'movies' and 'ratings' (inner join on 'movie_id')\n",
    "movie_ratings = pd.merge(movies, ratings)\n",
    "movie_ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T22:39:32.754807Z",
     "start_time": "2018-04-03T22:39:32.099Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(movies.shape)\n",
    "print(ratings.shape)\n",
    "print(movie_ratings.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"other-features\"></a>\n",
    "### OPTIONAL: Other Commonly Used Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T22:39:32.755987Z",
     "start_time": "2018-04-03T22:39:32.103Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# apply an arbitrary function to each value of a Pandas column, storing the result in a new column\n",
    "users['under30'] = users.age.apply(lambda age: age < 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T22:39:32.757086Z",
     "start_time": "2018-04-03T22:39:32.105Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# apply an arbitrary function to each row of a DataFrame, storing the result in a new column\n",
    "#  (remember that by default axis=0. Since we want to go row-by-row, we set axis=1)\n",
    "users['under30male'] = users.apply(lambda row: row.age < 30 and row.gender == 'M', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T22:39:32.758031Z",
     "start_time": "2018-04-03T22:39:32.109Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# map existing values to a different set of values\n",
    "users['is_male'] = users.gender.map({'F':0, 'M':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T22:39:32.759561Z",
     "start_time": "2018-04-03T22:39:32.113Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# replace all instances of a value in a column (must match entire value)\n",
    "ufo.State.replace('Fl', 'FL', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T22:39:32.760106Z",
     "start_time": "2018-04-03T22:39:32.115Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# string methods are accessed via 'str'\n",
    "ufo.State.str.upper()                               # converts to uppercase\n",
    "# checks for a substring\n",
    "ufo['Colors Reported'].str.contains('RED', na='False') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T22:39:32.760615Z",
     "start_time": "2018-04-03T22:39:32.119Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert a string to the datetime format (this is often slow -- consider doing it in the read_csv() method)\n",
    "ufo['Time'] = pd.to_datetime(ufo.Time)\n",
    "ufo.Time.dt.hour                        # datetime format exposes convenient attributes\n",
    "(ufo.Time.max() - ufo.Time.min()).days  # also allows you to do datetime \"math\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T22:39:32.761544Z",
     "start_time": "2018-04-03T22:39:32.122Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# setting and then removing an index\n",
    "ufo.set_index('Time', inplace=True)\n",
    "ufo.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T22:39:32.762460Z",
     "start_time": "2018-04-03T22:39:32.125Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# change the data type of a column\n",
    "drinks['beer'] = drinks.beer.astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T22:39:32.763656Z",
     "start_time": "2018-04-03T22:39:32.128Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create dummy variables for 'continent' and exclude first dummy column\n",
    "continent_dummies = pd.get_dummies(drinks.continent, prefix='cont').iloc[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T22:39:32.764771Z",
     "start_time": "2018-04-03T22:39:32.131Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# concatenate two DataFrames (axis=0 for rows, axis=1 for columns)\n",
    "drinks = pd.concat([drinks, continent_dummies], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"uncommon-features\"></a>\n",
    "### OPTIONAL: Other Less Used Features of Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T22:39:32.765825Z",
     "start_time": "2018-04-03T22:39:32.137Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# detecting duplicate rows\n",
    "users.duplicated()          # True if a row is identical to a previous row\n",
    "users.duplicated().sum()    # count of duplicates\n",
    "users[users.duplicated()]   # only show duplicates\n",
    "users.drop_duplicates()     # drop duplicate rows\n",
    "users.age.duplicated()      # check a single column for duplicates\n",
    "users.duplicated(['age', 'gender', 'zip_code']).sum()   # specify columns for finding duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T22:39:32.766967Z",
     "start_time": "2018-04-03T22:39:32.139Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert a range of values into descriptive groups\n",
    "drinks['beer_level'] = 'low'    # initially set all values to 'low'\n",
    "drinks.loc[drinks.beer.between(101, 200), 'beer_level'] = 'med'     # change 101-200 to 'med'\n",
    "drinks.loc[drinks.beer.between(201, 400), 'beer_level'] = 'high'    # change 201-400 to 'high'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T22:39:32.767805Z",
     "start_time": "2018-04-03T22:39:32.142Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# display a cross-tabulation of two Series\n",
    "pd.crosstab(drinks.continent, drinks.beer_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T22:39:32.768437Z",
     "start_time": "2018-04-03T22:39:32.145Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert 'beer_level' into the 'category' data type\n",
    "drinks['beer_level'] = pd.Categorical(drinks.beer_level, categories=['low', 'med', 'high'])\n",
    "drinks.sort_values('beer_level')   # sorts by the categorical ordering (low to high)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T22:39:32.769478Z",
     "start_time": "2018-04-03T22:39:32.148Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# limit which rows are read when reading in a file -- useful for large files!\n",
    "pd.read_csv('../data/drinks.csv', nrows=10)           # only read first 10 rows\n",
    "pd.read_csv('../data/drinks.csv', skiprows=[1, 2])    # skip the first two rows of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T22:39:32.770539Z",
     "start_time": "2018-04-03T22:39:32.151Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# write a DataFrame out to a CSV\n",
    "drinks.to_csv('drinks_updated.csv')                 # index is used as first column\n",
    "drinks.to_csv('drinks_updated.csv', index=False)    # ignore index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T22:39:32.771940Z",
     "start_time": "2018-04-03T22:39:32.154Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a DataFrame from a dictionary\n",
    "pd.DataFrame({'capital':['Montgomery', 'Juneau', 'Phoenix'], 'state':['AL', 'AK', 'AZ']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T22:39:32.772889Z",
     "start_time": "2018-04-03T22:39:32.157Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a DataFrame from a list of lists\n",
    "pd.DataFrame([['Montgomery', 'AL'], ['Juneau', 'AK'], ['Phoenix', 'AZ']], columns=['capital', 'state'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T22:39:32.773872Z",
     "start_time": "2018-04-03T22:39:32.161Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# randomly sample a DataFrame\n",
    "import numpy as np\n",
    "mask = np.random.rand(len(drinks)) < 0.66   # create a Series of booleans\n",
    "train = drinks[mask]                        # will contain around 66% of the rows\n",
    "test = drinks[~mask]                        # will contain the remaining rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T22:39:32.774851Z",
     "start_time": "2018-04-03T22:39:32.163Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# change the maximum number of rows and columns printed ('None' means unlimited)\n",
    "pd.set_option('max_rows', None)     # default is 60 rows\n",
    "pd.set_option('max_columns', None)  # default is 20 columns\n",
    "print(drinks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T22:39:32.775774Z",
     "start_time": "2018-04-03T22:39:32.166Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# reset options to defaults\n",
    "pd.reset_option('max_rows')\n",
    "pd.reset_option('max_columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T22:39:32.776717Z",
     "start_time": "2018-04-03T22:39:32.170Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# change the options temporarily (settings are restored when you exit the 'with' block)\n",
    "with pd.option_context('max_rows', None, 'max_columns', None):\n",
    "    print(drinks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<a id=\"summary\"></a>\n",
    "### Summary\n",
    "\n",
    "Amazingly, we only barely touched the surface of everything that Pandas offers! Do not worry if you do not remember most of it -- for now, just knowing what exists is key. Remember that the more you use Pandas to manipulate data, the more of these functions you will take interest in, look up, and remember.\n",
    "\n",
    "In this notebook, the most important things to familiarize yourself with are the basics:\n",
    "- Manipulating DataFrames and Series\n",
    "- Filtering Columns and Rows\n",
    "- Handling Missing Values\n",
    "- Split-Apply-Combine (this one takes some practice!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
